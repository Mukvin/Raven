# this script rotate the 22 adjusted tpch queries in workloads/tpch_100/tool/adjusted_tpch
# and produces 20000 queries in total
# in each adjusted sql file, there is a sql in section "[default]", it will be chosen by default
# if your engine has to further adjust the query, you can add another section in the syntax of:
#
# --[YOUR_ENGINE_NAME]
# select * from ...
#

# the [origin] section are queries generated by dbgen/qgen, with some simple syntax modifications
# as in workloads/tpch_100/tool/generate_query_script_non_duplicate_mode.py

import logging
import os
import re
import string

import yaml
from os import listdir
from os.path import isfile, join

if __name__ == '__main__':
    d = os.path.dirname(__file__)
    adjusted_dir = os.path.join(d, "adjusted_tpch")
    engine = 'kc'  # replace this with your own engine name

    guassian_dist = False
    query_count = 22


    def readfile(f):
        with open(f) as sql_file:
            lines = sql_file.readlines()
        full = str.join(os.linesep, lines)
        section = engine if full.__contains__(f"--[{engine}]") else 'default'

        started = False
        ret = ''
        for line in lines:
            if started:
                if re.match(r'\s*--\s*\[.+\]', line):
                    break
                else:
                    ret += os.linesep
                    ret += line

            if re.match(r'\s*--\s*\[' + section + r'\]', line):
                started = True

        return ret


    adjusted_queries = [readfile(join(adjusted_dir, f'tpch-query-{(i + 1)}.sql')) for i in range(0, 22)]
    # joined = ';\n\n'.join(adjusted_queries)
    # with open(f"../join.txt", 'w+') as file:
    #     file.write(joined)
    queries = [{"sql": adjusted_queries[i % 22], "id": f'query_{i}'} for i in range(0, query_count)]

    # generate random Gaussian values
    from random import seed
    from random import gauss

    # seed random number generator
    seed(1)
    # generate some Gaussian values
    at_seconds = []
while True:
    if len(at_seconds) >= query_count:
        break

    if guassian_dist:
        value = gauss(0, 1)
        if 2.5 > value > -2.5:  # -2.5 < value < 2.5 chance is about 97%
            at_seconds.append((value + 2.5) * 3600)  # distributed in 5 hours
    else:
        at_seconds.append(len(at_seconds) * 30)  # this is for testing

at_seconds.sort()

todo = []
for i in range(query_count):
    todo.append({"id": queries[i]["id"], "at_second": at_seconds[i], "sql": queries[i]["sql"]})

script = {"max_worker_num": 10000, "database": "raven_tpch_100_db", "queries": todo}
result = yaml.dump(script)
with open(f"../script.txt", 'w+') as file:
    yaml.dump(script, file)
